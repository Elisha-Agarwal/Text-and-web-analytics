{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT small/JJ red/JJ flower/NN)\n",
      "  flew/VBD\n",
      "  through/IN\n",
      "  (NP the/DT window/NN))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = [(\"The\", \"DT\"), (\"small\", \"JJ\"), (\"red\", \"JJ\"),(\"flower\", \"NN\"),\n",
    " (\"flew\", \"VBD\"), (\"through\", \"IN\"),  (\"the\", \"DT\"), (\"window\", \"NN\")]\n",
    "\n",
    "grammar = r\"\"\"\n",
    "    NP:{<DT|JJ|NN.*>+}\n",
    "\"\"\"\n",
    "\n",
    "chunkprofile = nltk.RegexpParser(grammar)\n",
    "result = chunkprofile.parse(sentence) \n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHINKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    The/DT\n",
      "    small/JJ\n",
      "    red/JJ\n",
      "    flower/NN\n",
      "    flew/VBD\n",
      "    through/IN\n",
      "    the/DT\n",
      "    window/NN))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = [(\"The\", \"DT\"), (\"small\", \"JJ\"), (\"red\", \"JJ\"),(\"flower\", \"NN\"), (\"flew\", \"VBD\"), (\"through\", \"IN\"),  (\"the\", \"DT\"), (\"window\", \"NN\")]\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NP:{<.*>+}         # Chunk everything\n",
    "  NP:{<VBD|IN>+}      # Chink sequences of JJ and NN\n",
    "  \"\"\"\n",
    "chunkprofile = nltk.RegexpParser(grammar)\n",
    "result = chunkprofile.parse(sentence) \n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAMED ENTITY RECOGNITION\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NE WASHINGTON/NNP)\n",
      "  --/:\n",
      "  In/IN\n",
      "  the/DT\n",
      "  wake/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  string/NN\n",
      "  of/IN\n",
      "  abuses/NNS\n",
      "  by/IN\n",
      "  (NE New/NNP York/NNP)\n",
      "  police/NN\n",
      "  officers/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1990s/CD\n",
      "  ,/,\n",
      "  (NE Loretta/NNP)\n",
      "  E./NNP\n",
      "  Lynch/NNP\n",
      "  ,/,\n",
      "  the/DT\n",
      "  top/JJ\n",
      "  federal/JJ\n",
      "  prosecutor/NN\n",
      "  in/IN\n",
      "  (NE Brooklyn/NNP)\n",
      "  ,/,\n",
      "  spoke/VBD\n",
      "  forcefully/RB\n",
      "  about/IN\n",
      "  the/DT\n",
      "  pain/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  broken/JJ\n",
      "  trust/NN\n",
      "  that/IN\n",
      "  African-Americans/NNP\n",
      "  felt/VBD\n",
      "  and/CC\n",
      "  said/VBD\n",
      "  the/DT\n",
      "  responsibility/NN\n",
      "  for/IN\n",
      "  repairing/VBG\n",
      "  generations/NNS\n",
      "  of/IN\n",
      "  miscommunication/NN\n",
      "  and/CC\n",
      "  mistrust/NN\n",
      "  fell/VBD\n",
      "  to/TO\n",
      "  law/NN\n",
      "  enforcement/NN\n",
      "  ./.)\n",
      "[Tree('NE', [('WASHINGTON', 'NNP')]), Tree('NE', [('New', 'NNP'), ('York', 'NNP')]), Tree('NE', [('Loretta', 'NNP')]), Tree('NE', [('Brooklyn', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "\n",
    "\n",
    "my_sent = \"WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\"\n",
    "\n",
    "parse_tree = nltk.ne_chunk(nltk.tag.pos_tag(nltk.word_tokenize(my_sent)), binary=True)  # POS tagging before chunking!\n",
    "\n",
    "parse_tree.draw()\n",
    "print(parse_tree)\n",
    "\n",
    "\n",
    "named_entities = []\n",
    "\n",
    "for t in parse_tree.subtrees():\n",
    "    if t.label() == 'NE':\n",
    "        named_entities.append(t)\n",
    "        # named_entities.append(list(t))  # if you want to save a list of tagged words instead of a tree\n",
    "\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('NE', [('WASHINGTON', 'NNP')]), Tree('NE', [('New', 'NNP'), ('York', 'NNP')]), Tree('NE', [('Loretta', 'NNP')]), Tree('NE', [('Brooklyn', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "named_entities = []\n",
    "\n",
    "for t in parse_tree.subtrees():\n",
    "    if t.label() == 'NE':\n",
    "        named_entities.append(t)\n",
    "        # named_entities.append(list(t))  # if you want to save a list of tagged words instead of a tree\n",
    "\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
